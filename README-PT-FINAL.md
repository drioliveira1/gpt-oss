<p align="center">
  ğŸ‡§ğŸ‡· <a href="./README-PT.md"><strong>PortuguÃªs</strong></a> |
  ğŸ‡ºğŸ‡¸ <a href="./README.md"><strong>English</strong></a>
</p>

# gpt-oss (TraduÃ§Ã£o para PortuguÃªs)

<p align="center">
  <a href="https://gpt-oss.com"><strong>Experimente gpt-oss</strong></a> Â·
  <a href="https://cookbook.openai.com/topic/gpt-oss"><strong>Guias</strong></a> Â·
  <a href="https://arxiv.org/abs/2508.10925"><strong>Ficha do modelo</strong></a> Â·
  <a href="https://openai.com/index/introducing-gpt-oss/"><strong>Blog da OpenAI</strong></a>
</p>
<p align="center">
  <strong>Baixe <a href="https://huggingface.co/openai/gpt-oss-120b">gpt-oss-120b</a> e <a href="https://huggingface.co/openai/gpt-oss-20b">gpt-oss-20b</a> no Hugging Face</strong>
</p>

---

Bem-vindo Ã  sÃ©rie **gpt-oss**, os [modelos de pesos abertos (open-weight)](https://openai.com/open-models/) da OpenAI, criados para **raciocÃ­nio avanÃ§ado**, **tarefas agenticas** (com uso de ferramentas) e **casos de uso versÃ¡teis de desenvolvedores**.

Estamos lanÃ§ando duas versÃµes desses modelos:

- **`gpt-oss-120b`** â€” para uso em produÃ§Ã£o, propÃ³sito geral e tarefas de raciocÃ­nio pesado, capaz de rodar em uma GPU de 80 GB (como NVIDIA H100 ou AMD MI300X) â€” 117 bilhÃµes de parÃ¢metros com 5,1 bilhÃµes ativos.  
- **`gpt-oss-20b`** â€” para menor latÃªncia e uso local ou especializado â€” 21 bilhÃµes de parÃ¢metros com 3,6 bilhÃµes ativos.  

Ambos foram treinados usando o [formato de resposta Harmony](https://github.com/openai/harmony) e **devem ser usados exclusivamente com esse formato**, caso contrÃ¡rio nÃ£o funcionarÃ£o corretamente.

---

## ğŸŒŸ Destaques

- **LicenÃ§a permissiva Apache 2.0:** use livremente, sem restriÃ§Ãµes de copyleft nem riscos de patente â€” ideal para experimentaÃ§Ã£o, personalizaÃ§Ã£o e implantaÃ§Ã£o comercial.  
- **EsforÃ§o de raciocÃ­nio configurÃ¡vel:** ajuste o nÃ­vel de raciocÃ­nio (baixo, mÃ©dio, alto) conforme o caso de uso e a latÃªncia desejada.  
- **Cadeia completa de pensamento (chain-of-thought):** acesso total ao processo de raciocÃ­nio do modelo â€” Ãºtil para depuraÃ§Ã£o e confianÃ§a nos resultados (nÃ£o destinado ao usuÃ¡rio final).  
- **AjustÃ¡vel (fine-tunable):** permite refinar o modelo para casos especÃ­ficos.  
- **Capacidades agenticas:** suporta chamadas de funÃ§Ã£o, navegaÃ§Ã£o web, execuÃ§Ã£o de cÃ³digo Python e saÃ­das estruturadas.  
- **QuantizaÃ§Ã£o MXFP4:** pÃ³s-treinamento com pesos MoE quantizados, permitindo que o `120b` rode numa GPU de 80 GB e o `20b` em ~16 GB.  

---

## ğŸ’¡ Uso RÃ¡pido com Transformers

```python
from transformers import pipeline
import torch

model_id = "openai/gpt-oss-20b"
pipe = pipeline("text-generation", model=model_id, torch_dtype="auto", device_map="auto")
messages = [{"role": "user", "content": "Explique mecÃ¢nica quÃ¢ntica de forma clara e concisa."}]
outputs = pipe(messages, max_new_tokens=256)
print(outputs[0]["generated_text"][-1])
```

---

## âš™ï¸ InstalaÃ§Ã£o

```bash
pip install gpt-oss
pip install gpt-oss[torch]
pip install gpt-oss[triton]
```

Para uso local:
```bash
git clone https://github.com/openai/gpt-oss.git
GPTOSS_BUILD_METAL=1 pip install -e ".[metal]"
```

---

## ğŸ“¥ Download dos Modelos

```bash
hf download openai/gpt-oss-120b --include "original/*" --local-dir gpt-oss-120b/
hf download openai/gpt-oss-20b --include "original/*" --local-dir gpt-oss-20b/
```

---

## ğŸ“˜ Sobre

Este repositÃ³rio fornece implementaÃ§Ãµes de referÃªncia em **PyTorch**, **Triton** e **Metal**, alÃ©m de ferramentas integradas (`browser` e `python`) que foram usadas durante o treinamento do modelo.

---

## ğŸŒ TraduÃ§Ãµes

ğŸ‡ºğŸ‡¸ **[VersÃ£o Original em InglÃªs (README.md)](./README.md)**  
Documento bilÃ­ngue sincronizado â€” acesse a versÃ£o oficial em inglÃªs.

ğŸ‘¤ **TraduÃ§Ã£o:** Adriano De Oliveira (drioliveira1)  
ğŸ”— **RepositÃ³rio:** [github.com/drioliveira1/gpt-oss](https://github.com/drioliveira1/gpt-oss)
